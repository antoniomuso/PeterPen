{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovanni/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = ['AcX', 'AcY', 'AcZ', 'Pres', 'GyX', 'GyY', 'GyZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lines.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('lines_2.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "\n",
    "for elem in range(len(data_lines)):\n",
    "    for arr in range(len(data_lines[elem])):\n",
    "        tmp = []\n",
    "        for f in features_name:\n",
    "            tmp.append(data_lines[elem][arr][f])\n",
    "        data_lines[elem][arr] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('circles.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "\n",
    "for elem in range(len(data_circles)):\n",
    "    for arr in range(len(data_circles[elem])):\n",
    "        tmp = []\n",
    "        for f in features_name:\n",
    "            tmp.append(data_circles[elem][arr][f])\n",
    "        data_circles[elem][arr] = tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lines.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('lines_2.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "    \n",
    "def new_scale_df(data_frame, gyro, accl, pres):\n",
    "    \n",
    "    def scale(value, max_, min_):\n",
    "        value -= min_\n",
    "        value /= max_ - min_\n",
    "    \n",
    "    copy = data_frame.copy() \n",
    "    scale(copy['AcX'], accl, -accl)\n",
    "    scale(copy['AcY'], accl, -accl)\n",
    "    scale(copy['AcZ'], accl, -accl)\n",
    "    scale(copy['GyX'], gyro, -gyro)\n",
    "    scale(copy['GyY'], gyro, -gyro)\n",
    "    scale(copy['GyZ'], gyro, -gyro)\n",
    "    scale(copy['Pres'], pres, 0)\n",
    "\n",
    "    return copy\n",
    "    \n",
    "def generator(features_name, data, labels):\n",
    "    assert len(data) == len(labels)\n",
    "    while True:\n",
    "        for elem in range(len(data)):\n",
    "            word_array = []\n",
    "            for arr in range(len(data[elem])):\n",
    "                cp_data = new_scale_df(data[elem][arr], 250, 2, 1024)\n",
    "                tmp = []\n",
    "                for f in features_name:\n",
    "                    tmp.append(cp_data[f])\n",
    "                word_array.append(tmp)\n",
    "            yield np.reshape(np.array(word_array), (1, len(word_array), 7)), [labels[elem]]\n",
    "\n",
    "g_lines = generator(features_name, data_lines, [1] * len(data_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('circles.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "    \n",
    "g_circles = generator(features_name, data_circles, [0] * len(data_circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dario.json', 'r') as f:\n",
    "    data_d = json.load(f)\n",
    "g_dario = generator(features_name, data_d[:-3], [1] * 7)\n",
    "g_dario_test = generator(features_name, data_d[-3:], [1] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('antonio.json', 'r') as f:\n",
    "    data_a = json.load(f)\n",
    "    \n",
    "g_antonio = generator(features_name, data_a[:-3], [0] * 8)\n",
    "g_antonio_test = generator(features_name, data_a[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('taraz.json', 'r') as f:\n",
    "    data_t = json.load(f)\n",
    "    \n",
    "g_taraz = generator(features_name, data_t[:-3], [0] * 7)\n",
    "g_taraz_test = generator(features_name, data_t[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('giovanni.json', 'r') as f:\n",
    "    data_g = json.load(f)\n",
    "    \n",
    "g_giovanni = generator(features_name, data_g[:-3], [0] * 5)\n",
    "g_giovanni_test = generator(features_name, data_g[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_generator(g1, g2):\n",
    "    while True:\n",
    "        yield next(g1)\n",
    "        yield next(g2)\n",
    "\n",
    "g_mix = mix_generator(g_lines, g_circles)\n",
    "g_dario_giovanni = mix_generator(g_dario, g_giovanni)\n",
    "g_dario_antonio = mix_generator(g_dario, g_antonio)\n",
    "g_dario_taraz = mix_generator(g_dario, g_taraz)\n",
    "g_dario_giovanni_antonio = mix_generator(g_dario_giovanni, g_dario_antonio)\n",
    "g_dario_tutti = mix_generator(g_dario_giovanni_antonio, g_dario_taraz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_one_against_all(path_genuine, paths_impostors):\n",
    "    with open(path_genuine, 'r') as f:\n",
    "        genuine_data = json.load(f)\n",
    "        \n",
    "    train_ratio = round(len(genuine_data) / 5)\n",
    "    assert len(genuine_data[:-train_ratio]) + len(genuine_data[-train_ratio:]) == len(genuine_data)\n",
    "    genuine_generator = generator(features_name, genuine_data[:-train_ratio], [1] * (len(genuine_data) - train_ratio))\n",
    "    genuine_generator_test = generator(features_name, genuine_data[-train_ratio:], [1] * train_ratio)\n",
    "    \n",
    "    generator_all = genuine_generator\n",
    "    generator_all_test = genuine_generator_test\n",
    "    \n",
    "    for path in paths_impostors:\n",
    "        with open(path, 'r') as f:\n",
    "            impostor_data = json.load(f)\n",
    "        train_ratio = round(len(impostor_data) / 5)\n",
    "        assert len(impostor_data[:-train_ratio]) + len(impostor_data[-train_ratio:]) == len(impostor_data)\n",
    "        generator_all = mix_generator(generator_all, generator(features_name, impostor_data[:-train_ratio], [0] * (len(impostor_data) - train_ratio)))\n",
    "        generator_all_test = mix_generator(generator_all_test, generator(features_name, impostor_data[-train_ratio:], [0] * train_ratio))\n",
    "        \n",
    "    return generator_all, generator_all_test\n",
    "\n",
    "impostors = ['giovanni.json', 'taraz.json']\n",
    "g_dario_impostors, g_dario_impostors_test = generator_one_against_all('dario.json', impostors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario = Sequential()\n",
    "model_dario.add(LSTM(batch_size=1, input_shape=(None, 7), units=200, activation=\"sigmoid\", return_sequences=False, recurrent_activation=\"hard_sigmoid\"))\n",
    "model_dario.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 7s 178ms/step - loss: 0.6387 - acc: 0.6429\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.5123 - acc: 0.7619\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 0.4916 - acc: 0.7381\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 6s 148ms/step - loss: 0.4558 - acc: 0.7619\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.4475 - acc: 0.7381\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.3984 - acc: 0.7619\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 6s 144ms/step - loss: 0.4245 - acc: 0.7619\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.3615 - acc: 0.8810\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.3711 - acc: 0.8571\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.3603 - acc: 0.8571\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.3318 - acc: 0.8810\n",
      "Epoch 12/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.3066 - acc: 0.8810\n",
      "Epoch 13/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.3353 - acc: 0.9048\n",
      "Epoch 14/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.2818 - acc: 0.9524\n",
      "Epoch 15/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 0.2732 - acc: 0.9286\n",
      "Epoch 16/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.2495 - acc: 0.9524\n",
      "Epoch 17/30\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.2855 - acc: 0.9286\n",
      "Epoch 18/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.2291 - acc: 0.9286\n",
      "Epoch 19/30\n",
      "42/42 [==============================] - 6s 152ms/step - loss: 0.2209 - acc: 0.9524\n",
      "Epoch 20/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.2401 - acc: 0.9286\n",
      "Epoch 21/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.2066 - acc: 0.9286\n",
      "Epoch 22/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.1796 - acc: 0.9762\n",
      "Epoch 23/30\n",
      "42/42 [==============================] - 6s 145ms/step - loss: 0.2207 - acc: 0.9286\n",
      "Epoch 24/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.1631 - acc: 0.9762\n",
      "Epoch 25/30\n",
      "42/42 [==============================] - 6s 149ms/step - loss: 0.1678 - acc: 0.9762\n",
      "Epoch 26/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.1935 - acc: 0.9524\n",
      "Epoch 27/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.1385 - acc: 0.9762\n",
      "Epoch 28/30\n",
      "42/42 [==============================] - 6s 147ms/step - loss: 0.1338 - acc: 0.9762\n",
      "Epoch 29/30\n",
      "42/42 [==============================] - 6s 146ms/step - loss: 0.1722 - acc: 0.9524\n",
      "Epoch 30/30\n",
      "42/42 [==============================] - 6s 150ms/step - loss: 0.1180 - acc: 0.9762\n"
     ]
    }
   ],
   "source": [
    "hist = model_dario.fit_generator(g_dario_impostors, epochs=30, steps_per_epoch=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24814651627093554, 0.8333333333333334]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dario.evaluate_generator(g_dario_impostors_test, verbose=1, steps=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 26ms/step\n",
      "3/3 [==============================] - 0s 33ms/step\n",
      "3/3 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.47930579880873364, 0.6666666666666666],\n",
       " [0.10888240362207095, 1.0],\n",
       " [0.04201492046316465, 1.0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dario = model_dario.evaluate_generator(g_dario_test, verbose=1, steps=3)\n",
    "out_giovanni = model_dario.evaluate_generator(g_giovanni_test, verbose=1, steps=3)\n",
    "out_taraz = model_dario.evaluate_generator(g_taraz_test, verbose=1, steps=3)\n",
    "\n",
    "out_dario, out_giovanni, out_taraz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario.save(\"model_dario.h5\")\n",
    "del model_dario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario_reloaded = load_model(\"model_dario.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47930579880873364, 0.6666666666666666]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dario_reloaded = model_dario_reloaded.evaluate_generator(g_dario_test, verbose=1, steps=3)\n",
    "\n",
    "out_dario_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUA SOTTO C'Ãˆ ROBA VECCHIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('lines.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(data)):\n",
    "    dfl = pd.DataFrame(data = data[i])\n",
    "    for j in range(len(dfl)):\n",
    "        X_train.append(dfl.iloc[j].values)\n",
    "        y_train.append(0)           # lines\n",
    " \n",
    "\n",
    "with open('circles.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dfc = pd.DataFrame(data = data)    \n",
    "for i in range(len(data)):\n",
    "    dfc = pd.DataFrame(data = data[i])\n",
    "    for j in range(len(dfc)):\n",
    "        X_train.append(dfc.iloc[j].values)\n",
    "        y_train.append(1)           # circles\n",
    "    \n",
    "    \n",
    "with open('mix.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df = pd.DataFrame(data = data)    \n",
    "mix = []\n",
    "for i in range(len(df)):\n",
    "    mix.append(pd.DataFrame(data = data[i]))\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(X_train).values\n",
    "y_train1 = np.array(y_train[:158])\n",
    "X_train = np.reshape(X_train, (1, X_train.shape[0], 7))\n",
    "\n",
    "X_train1 = np.reshape(X_train1, (1, -1, 7))\n",
    "y_train1 = np.reshape(y_train1, (1, y_train1.shape[0], 1))\n",
    "print(X_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(batch_size=1, input_shape=(None, 7), units=200, activation=\"sigmoid\", return_sequences=True, recurrent_activation=\"hard_sigmoid\"))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(X_train1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "hist = model.fit(X_train1, y_train1, batch_size=1, epochs=10, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
