{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pad_file(file, file_out):\n",
    "    def scale(value, max_, min_):\n",
    "        return (value - min_) / (max_ - min_)\n",
    "    \n",
    "    accl = 2\n",
    "    gyro = 250\n",
    "    \n",
    "    max_len = 800\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for wIndex in range(len(data)):\n",
    "        data[wIndex] = np.array(data[wIndex])\n",
    "        \n",
    "        for vIndex in range(len(data[wIndex])):\n",
    "            data[wIndex][vIndex][0] = scale(data[wIndex][vIndex][0], accl, -accl)\n",
    "            data[wIndex][vIndex][1] = scale(data[wIndex][vIndex][1], accl, -accl)\n",
    "            data[wIndex][vIndex][2] = scale(data[wIndex][vIndex][2], accl, -accl)\n",
    "            data[wIndex][vIndex][3] = scale(data[wIndex][vIndex][3], 1024, 0)\n",
    "            data[wIndex][vIndex][4] = scale(data[wIndex][vIndex][4], gyro, -gyro)\n",
    "            data[wIndex][vIndex][5] = scale(data[wIndex][vIndex][5], gyro, -gyro)\n",
    "            data[wIndex][vIndex][6] = scale(data[wIndex][vIndex][6], gyro, -gyro)\n",
    "            \n",
    "        data[wIndex] = np.reshape(data[wIndex], (len(data[wIndex]) * 7, ))\n",
    "        data[wIndex] = np.pad(data[wIndex], (0, max_len * 7 - len(data[wIndex])), 'edge')\n",
    "        data[wIndex] = np.reshape(data[wIndex], (max_len, 7))\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    with open(file_out, 'w') as fw:\n",
    "        json.dump(data.tolist(), fw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_file(file, file_out):\n",
    "    max_len = 600\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    for wIndex in range(len(data)):\n",
    "        data[wIndex] = np.array(data[wIndex])\n",
    "        data[wIndex] = np.reshape(data[wIndex], (len(data[wIndex]) * 7, ))\n",
    "        data[wIndex] = np.pad(data[wIndex], (0, max_len * 7 - len(data[wIndex])), 'edge')\n",
    "        data[wIndex] = np.reshape(data[wIndex], (max_len, 7))\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    with open(file_out, 'w') as fw:\n",
    "        json.dump(data.tolist(), fw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dati/dati_con_penna/concatenati/dario.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9c4f9ac4660c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mscale_pad_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati/dati_con_penna/concatenati/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati/dati_con_penna/concatenati/scaled/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_scaled.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mpad_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati/dati_con_penna/concatenati/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../dati/dati_con_penna/concatenati/pad/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_pad.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-55c98d095d4f>\u001b[0m in \u001b[0;36mscale_pad_file\u001b[0;34m(file, file_out)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dati/dati_con_penna/concatenati/dario.json'"
     ]
    }
   ],
   "source": [
    "for f in os.listdir('../dati/dati_con_penna/concatenati/'):\n",
    "    if f.endswith('.json'):\n",
    "        scale_pad_file(os.path.join('../dati/dati_con_penna/concatenati/', f), os.path.join('../dati/dati_con_penna/concatenati/scaled/', f)[:-5] + '_scaled.json')\n",
    "        pad_file(os.path.join('../dati/dati_con_penna/concatenati/', f), os.path.join('../dati/dati_con_penna/concatenati/pad/', f)[:-5] + '_pad.json')\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
