{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "from keras.layers import Dense, LSTM, Dropout, Masking\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "\n",
    "for elem in range(len(data_lines)):\n",
    "    for arr in range(len(data_lines[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_lines[elem][arr][f])\n",
    "        data_lines[elem][arr] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "\n",
    "for elem in range(len(data_circles)):\n",
    "    for arr in range(len(data_circles[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_circles[elem][arr][f])\n",
    "        data_circles[elem][arr] = tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "    \n",
    "\n",
    "def generator(data, labels):\n",
    "    assert len(data) == len(labels)\n",
    "    while True:\n",
    "        for elem in range(len(data)):\n",
    "            #word_array = []\n",
    "            #for arr in range(len(data[elem])):\n",
    "            #    tmp = []\n",
    "            #    for f in range(7):\n",
    "            #        tmp.append(data[elem][arr][f])\n",
    "            #    word_array.append(tmp)\n",
    "            yield np.array(data[elem]), np.array(labels[elem])\n",
    "\n",
    "g_lines = generator(data_lines, [1] * len(data_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "    \n",
    "g_circles = generator(data_circles, [0] * len(data_circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_recog = 'Antonio_pad_concat_antonio_recognition_pad.json'\n",
    "file_path = '../dati/scrittura_di_computer/pad/'\n",
    "labelled_data_d, labelled_data_g = [], []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if os.path.splitext(file)[1] != '.json': continue\n",
    "    if file_recog == file: continue\n",
    "    with open(os.path.join(file_path, file), 'r') as f:\n",
    "        data_g = json.load(f)\n",
    "    for i in range(len(data_g)):\n",
    "        labelled_data_g.append((data_g[i], 0))\n",
    "        \n",
    "        \n",
    "with open(os.path.join(file_path, file_recog), 'r') as f:\n",
    "    data_r = json.load(f)\n",
    "for i in range(len(data_r)):\n",
    "    labelled_data_d.append((data_r[i], 1))\n",
    "    \n",
    "def xy_data(labelled_data):\n",
    "    x_data, y_labels = [], []\n",
    "    for i in labelled_data:\n",
    "        x_data.append(i[0])\n",
    "        y_labels.append(i[1])\n",
    "        \n",
    "    return np.array(x_data), np.array(y_labels)\n",
    "\n",
    "labelled_data_dg = labelled_data_d *2  + labelled_data_g  \n",
    "random.shuffle(labelled_data_dg)\n",
    "\n",
    "data_dg, label_dg = xy_data(labelled_data_dg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    model.add(LSTM(input_shape=(1000, 7), units=64, activation=\"sigmoid\", return_sequences=True, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(LSTM(units=128, activation=\"sigmoid\", return_sequences=False, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network = KerasClassifier(build_fn=create_model, \n",
    "#                                 epochs=4,\n",
    "#                                 steps_per_epoch=140,\n",
    "#                                 validation_split=0.2,\n",
    "#                                 validation_steps=36,\n",
    "#                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model_dario, show_shapes=True, to_file='lstm_dropout_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model_dario.fit_generator(g_dario_impostors, epochs=5, steps_per_epoch=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 558 samples, validate on 276 samples\n",
      "Epoch 1/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.5082 - acc: 0.7885 - val_loss: 0.3716 - val_acc: 0.8732\n",
      "Epoch 2/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.4587 - acc: 0.8297 - val_loss: 0.3443 - val_acc: 0.8732\n",
      "Epoch 3/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.4262 - acc: 0.8297 - val_loss: 0.3301 - val_acc: 0.8732\n",
      "Epoch 4/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.3788 - acc: 0.8280 - val_loss: 0.2954 - val_acc: 0.8732\n",
      "Epoch 5/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.3357 - acc: 0.8441 - val_loss: 0.3054 - val_acc: 0.8732\n",
      "Epoch 6/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.3074 - acc: 0.8602 - val_loss: 0.2191 - val_acc: 0.9348\n",
      "Epoch 7/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.2660 - acc: 0.9014 - val_loss: 0.1985 - val_acc: 0.9420\n",
      "Epoch 8/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.2482 - acc: 0.8996 - val_loss: 0.1803 - val_acc: 0.9420\n",
      "Epoch 9/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.2484 - acc: 0.9032 - val_loss: 0.2049 - val_acc: 0.9348\n",
      "Epoch 10/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.2089 - acc: 0.9229 - val_loss: 0.1526 - val_acc: 0.9529\n",
      "Epoch 11/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.1973 - acc: 0.9211 - val_loss: 0.1524 - val_acc: 0.9457\n",
      "Epoch 12/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1840 - acc: 0.9427 - val_loss: 0.2570 - val_acc: 0.8913\n",
      "Epoch 13/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.1687 - acc: 0.9337 - val_loss: 0.1328 - val_acc: 0.9493\n",
      "Epoch 14/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.1836 - acc: 0.9211 - val_loss: 0.1929 - val_acc: 0.9275\n",
      "Epoch 15/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1557 - acc: 0.9427 - val_loss: 0.2912 - val_acc: 0.9094\n",
      "Epoch 16/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.1691 - acc: 0.9373 - val_loss: 0.1705 - val_acc: 0.9384\n",
      "Epoch 17/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.1366 - acc: 0.9588 - val_loss: 0.1101 - val_acc: 0.9565\n",
      "Epoch 18/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1219 - acc: 0.9534 - val_loss: 0.1128 - val_acc: 0.9493\n",
      "Epoch 19/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.1720 - acc: 0.9247 - val_loss: 0.1298 - val_acc: 0.9493\n",
      "Epoch 20/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1760 - acc: 0.9301 - val_loss: 0.0959 - val_acc: 0.9638\n",
      "Epoch 21/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1380 - acc: 0.9355 - val_loss: 0.0916 - val_acc: 0.9638\n",
      "Epoch 22/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1237 - acc: 0.9570 - val_loss: 0.0837 - val_acc: 0.9674\n",
      "Epoch 23/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0903 - acc: 0.9713 - val_loss: 0.1063 - val_acc: 0.9565\n",
      "Epoch 24/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.0676 - acc: 0.9821 - val_loss: 0.3209 - val_acc: 0.8986\n",
      "Epoch 25/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.1161 - acc: 0.9588 - val_loss: 0.0771 - val_acc: 0.9601\n",
      "Epoch 26/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1381 - acc: 0.9444 - val_loss: 0.1521 - val_acc: 0.9384\n",
      "Epoch 27/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0557 - acc: 0.9803 - val_loss: 0.0638 - val_acc: 0.9783\n",
      "Epoch 28/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1198 - acc: 0.9373 - val_loss: 0.0737 - val_acc: 0.9638\n",
      "Epoch 29/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0710 - acc: 0.9767 - val_loss: 0.0834 - val_acc: 0.9638\n",
      "Epoch 30/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.1411 - acc: 0.9373 - val_loss: 0.0563 - val_acc: 0.9819\n",
      "Epoch 31/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.0479 - acc: 0.9821 - val_loss: 0.0435 - val_acc: 0.9819\n",
      "Epoch 32/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.1289 - acc: 0.9570 - val_loss: 0.0403 - val_acc: 0.9819\n",
      "Epoch 33/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0476 - acc: 0.9857 - val_loss: 0.0473 - val_acc: 0.9819\n",
      "Epoch 34/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0987 - acc: 0.9677 - val_loss: 0.0366 - val_acc: 0.9891\n",
      "Epoch 35/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.1167 - acc: 0.9731 - val_loss: 0.2041 - val_acc: 0.9203\n",
      "Epoch 36/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0612 - acc: 0.9821 - val_loss: 0.0783 - val_acc: 0.9710\n",
      "Epoch 37/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.0380 - acc: 0.9857 - val_loss: 0.0296 - val_acc: 0.9855\n",
      "Epoch 38/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0463 - acc: 0.9875 - val_loss: 0.5322 - val_acc: 0.8732\n",
      "Epoch 39/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0764 - acc: 0.9767 - val_loss: 0.0284 - val_acc: 0.9928\n",
      "Epoch 40/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.1097 - acc: 0.9642 - val_loss: 0.0268 - val_acc: 0.9891\n",
      "Epoch 41/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0379 - acc: 0.9875 - val_loss: 0.0286 - val_acc: 0.9928\n",
      "Epoch 42/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0730 - acc: 0.9803 - val_loss: 0.1124 - val_acc: 0.9529\n",
      "Epoch 43/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0181 - acc: 0.9946 - val_loss: 0.0156 - val_acc: 0.9928\n",
      "Epoch 44/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.0480 - acc: 0.9875 - val_loss: 0.0278 - val_acc: 0.9855\n",
      "Epoch 45/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0793 - acc: 0.9659 - val_loss: 0.0847 - val_acc: 0.9601\n",
      "Epoch 46/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0146 - acc: 0.9946 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 47/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 48/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1097 - acc: 0.9516 - val_loss: 0.0298 - val_acc: 0.9891\n",
      "Epoch 49/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 0.9420\n",
      "Epoch 50/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0239 - acc: 0.9928 - val_loss: 0.0149 - val_acc: 0.9928\n",
      "Epoch 51/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0868 - acc: 0.9821 - val_loss: 0.0278 - val_acc: 0.9891\n",
      "Epoch 52/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 53/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1192 - acc: 0.9659 - val_loss: 0.0212 - val_acc: 0.9928\n",
      "Epoch 54/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
      "Epoch 55/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 56/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0837 - acc: 0.9803 - val_loss: 0.0204 - val_acc: 0.9928\n",
      "Epoch 57/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 0.9964\n",
      "Epoch 58/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 59/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1108 - acc: 0.9749 - val_loss: 0.0115 - val_acc: 0.9964\n",
      "Epoch 60/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0155 - val_acc: 0.9928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 0.9891\n",
      "Epoch 62/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.5731 - val_acc: 0.8804\n",
      "Epoch 63/110\n",
      "558/558 [==============================] - 34s 60ms/step - loss: 0.2551 - acc: 0.9391 - val_loss: 0.0156 - val_acc: 0.9964\n",
      "Epoch 64/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9964\n",
      "Epoch 65/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 66/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 8.9206e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 67/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1746 - acc: 0.9624 - val_loss: 0.1178 - val_acc: 0.9529\n",
      "Epoch 68/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0192 - acc: 0.9946 - val_loss: 0.0132 - val_acc: 0.9964\n",
      "Epoch 69/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 70/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 6.9295e-04 - acc: 1.0000 - val_loss: 9.5572e-04 - val_acc: 1.0000\n",
      "Epoch 71/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 4.9084e-04 - acc: 1.0000 - val_loss: 6.9925e-04 - val_acc: 1.0000\n",
      "Epoch 72/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1491 - acc: 0.9695 - val_loss: 0.0209 - val_acc: 0.9928\n",
      "Epoch 73/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0082 - acc: 0.9982 - val_loss: 0.0446 - val_acc: 0.9783\n",
      "Epoch 74/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0428 - acc: 0.9875 - val_loss: 0.0111 - val_acc: 0.9964\n",
      "Epoch 75/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "Epoch 76/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 6.5916e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 77/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0609 - acc: 0.9803 - val_loss: 0.0175 - val_acc: 0.9964\n",
      "Epoch 78/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.0774 - acc: 0.9785 - val_loss: 0.0207 - val_acc: 0.9891\n",
      "Epoch 79/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
      "Epoch 80/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 81/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 5.6811e-04 - acc: 1.0000 - val_loss: 8.1882e-04 - val_acc: 1.0000\n",
      "Epoch 82/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 0.2302 - acc: 0.9552 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 83/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 7.0900e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 84/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 5.4849e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 85/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 4.8138e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 86/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.0374 - acc: 0.9910 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 87/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0023 - acc: 0.9982 - val_loss: 7.3612e-04 - val_acc: 1.0000\n",
      "Epoch 88/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1417 - acc: 0.9713 - val_loss: 0.0408 - val_acc: 0.9855\n",
      "Epoch 89/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0188 - val_acc: 0.9928\n",
      "Epoch 90/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 91/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 4.7619e-04 - acc: 1.0000 - val_loss: 6.6448e-04 - val_acc: 1.0000\n",
      "Epoch 92/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 3.1764e-04 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 0.9964\n",
      "Epoch 93/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.1309 - acc: 0.9695 - val_loss: 0.0074 - val_acc: 0.9964\n",
      "Epoch 94/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "Epoch 95/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 4.1851e-04 - acc: 1.0000 - val_loss: 4.5300e-04 - val_acc: 1.0000\n",
      "Epoch 96/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 1.8750e-04 - acc: 1.0000 - val_loss: 2.7110e-04 - val_acc: 1.0000\n",
      "Epoch 97/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0835 - acc: 0.9731 - val_loss: 0.0348 - val_acc: 0.9891\n",
      "Epoch 98/110\n",
      "558/558 [==============================] - 35s 62ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9964\n",
      "Epoch 99/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 9.9104e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "Epoch 100/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 3.8763e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9964\n",
      "Epoch 101/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 0.0608 - acc: 0.9839 - val_loss: 0.0935 - val_acc: 0.9601\n",
      "Epoch 102/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0149 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 1.0000\n",
      "Epoch 103/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 104/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 3.0425e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 105/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 2.8914e-04 - acc: 1.0000 - val_loss: 6.2684e-04 - val_acc: 1.0000\n",
      "Epoch 106/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 0.0735 - acc: 0.9821 - val_loss: 0.0258 - val_acc: 0.9855\n",
      "Epoch 107/110\n",
      "558/558 [==============================] - 34s 61ms/step - loss: 9.8022e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 108/110\n",
      "558/558 [==============================] - 34s 62ms/step - loss: 4.8030e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 109/110\n",
      "558/558 [==============================] - 35s 63ms/step - loss: 2.5877e-04 - acc: 1.0000 - val_loss: 2.7240e-04 - val_acc: 1.0000\n",
      "Epoch 110/110\n",
      "160/558 [=======>......................] - ETA: 20s - loss: 2.2707e-04 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "cb = keras.callbacks.TensorBoard(log_dir='/usr/Graph', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "hist = model.fit(x = data_dg, y = label_dg, epochs=110, batch_size=32, callbacks=[cb],validation_split=0.33)\n",
    "\n",
    "#out = cross_val_score(neural_network, data_dg, label_dg, cv=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('model_antonio_good_performance_65_instanze.h5')\n",
    "#out\n",
    "#!git config --global user.email \"antoniomusolino007@gmail.com\"\n",
    "#!git stash --include-untracked\n",
    "#!git add ../.\n",
    "#!git commit -m 'aggiunte nuove mie instanze'\n",
    "#!git pull\n",
    "#!git push\n",
    "#print(out)\n",
    "#out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_mean (curve):\n",
    "    mean = [0]* len(curve)\n",
    "    mean[0] = curve[0]\n",
    "    for i in range(1,len(curve)):\n",
    "        mean[i] = ((mean[i-1] )*i + out[i])/(i+1)\n",
    "    return mean\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model_Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Learn', 'Test'], loc='lower right')\n",
    "plt.savefig('./150_epoch_accuracy_new_data_Manuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./model_accuracy_40Epoch_scaled',quality=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#model.save('model_giulio_good_performance_23.h5')\n",
    "#plt.savefig('./model_loss_40Epoch_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_manuel = load_model('model_manuel_good_performance.h5')\n",
    "model_giovanni = load_model('model_giovanni_good_performance.h5')\n",
    "model_dario_reloaded = load_model(\"model_dario_good_performance.h5\")\n",
    "model_antonio_reloaded = load_model('model_antonio_good_performance.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = xy_data(labelled_data_g)\n",
    "x1, y1, = xy_data(labelled_data_d)\n",
    "out_dario_reloaded = model_dario_reloaded.evaluate(x, y)\n",
    "out_dario_reloaded2 = model_dario_reloaded.evaluate(x1, y1)\n",
    "\n",
    "print(out_dario_reloaded)\n",
    "print(out_dario_reloaded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "with open(os.path.join(file_path ,'antonio_recognition_pad.json'), 'r') as f:\n",
    "    attack = json.load(f)\n",
    "\n",
    "attack = np.array(attack)\n",
    "print(attack.shape)\n",
    "\n",
    "data_value = np.concatenate((data_dg, attack))\n",
    "lable_value = np.concatenate((label_dg, np.ones(attack.shape[0])))\n",
    "\n",
    "model_antonio_reloaded.predict(attack)\n",
    "#fpr_keras, tpr_keras, thresholds_keras = roc_curve(label_dg, predict)\n",
    "#print(model_giovanni.evaluate(data_dg, label_dg))\n",
    "#print(model_manuel.evaluate(data_dg, label_dg))\n",
    "#print(model_antonio_reloaded.evaluate(data_dg, label_dg))\n",
    "#attack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc = metrics.auc(fpr_keras, tpr_keras)\n",
    "\n",
    "plt.plot(fpr_keras,tpr_keras,'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.title('ROC curve')\n",
    "plt.ylabel('tpr')\n",
    "plt.xlabel('fpr')\n",
    "plt.legend(['curve'], loc='lower right')\n",
    "#plt.savefig('ROC_curve_Manuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
