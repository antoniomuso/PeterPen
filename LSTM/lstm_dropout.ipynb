{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "from keras.layers import Dense, LSTM, Dropout, Masking\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "\n",
    "for elem in range(len(data_lines)):\n",
    "    for arr in range(len(data_lines[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_lines[elem][arr][f])\n",
    "        data_lines[elem][arr] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "\n",
    "for elem in range(len(data_circles)):\n",
    "    for arr in range(len(data_circles[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_circles[elem][arr][f])\n",
    "        data_circles[elem][arr] = tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "    \n",
    "\n",
    "def generator(data, labels):\n",
    "    assert len(data) == len(labels)\n",
    "    while True:\n",
    "        for elem in range(len(data)):\n",
    "            #word_array = []\n",
    "            #for arr in range(len(data[elem])):\n",
    "            #    tmp = []\n",
    "            #    for f in range(7):\n",
    "            #        tmp.append(data[elem][arr][f])\n",
    "            #    word_array.append(tmp)\n",
    "            yield np.array(data[elem]), np.array(labels[elem])\n",
    "\n",
    "g_lines = generator(data_lines, [1] * len(data_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "    \n",
    "g_circles = generator(data_circles, [0] * len(data_circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_recog = 'Dario_pad.json'\n",
    "file_path = '../dati/scrittura_di_computer/pad/'\n",
    "labelled_data_d, labelled_data_g = [], []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file_recog == file: continue\n",
    "    with open(os.path.join(file_path, file), 'r') as f:\n",
    "        data_g = json.load(f)\n",
    "    for i in range(len(data_g)):\n",
    "        labelled_data_g.append((data_g[i], 0))\n",
    "        \n",
    "        \n",
    "with open(os.path.join(file_path, file_recog), 'r') as f:\n",
    "    data_r = json.load(f)\n",
    "for i in range(len(data_r)):\n",
    "    labelled_data_d.append((data_r[i], 1))\n",
    "    \n",
    "def xy_data(labelled_data):\n",
    "    x_data, y_labels = [], []\n",
    "    for i in labelled_data:\n",
    "        x_data.append(i[0])\n",
    "        y_labels.append(i[1])\n",
    "        \n",
    "    return np.array(x_data), np.array(y_labels)\n",
    "\n",
    "labelled_data_dg = labelled_data_d + labelled_data_g  \n",
    "random.shuffle(labelled_data_dg)\n",
    "\n",
    "data_dg, label_dg = xy_data(labelled_data_dg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    model.add(LSTM(input_shape=(600, 7), units=200, activation=\"sigmoid\", return_sequences=True, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(LSTM(units=200, activation=\"sigmoid\", return_sequences=False, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network = KerasClassifier(build_fn=create_model, \n",
    "#                                 epochs=4,\n",
    "#                                 steps_per_epoch=140,\n",
    "#                                 validation_split=0.2,\n",
    "#                                 validation_steps=36,\n",
    "#                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model_dario, show_shapes=True, to_file='lstm_dropout_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model_dario.fit_generator(g_dario_impostors, epochs=5, steps_per_epoch=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 225 samples, validate on 112 samples\n",
      "Epoch 1/40\n",
      "32/33 [============================>.] - ETA: 1s - loss: 0.3691 - acc: 0.8696"
     ]
    }
   ],
   "source": [
    "model_dario = create_model()\n",
    "hist = model_dario.fit(x = data_dg, y = label_dg, epochs=40, steps_per_epoch=100, validation_split=0.33, validation_steps=65)\n",
    "\n",
    "#out = cross_val_score(neural_network, data_dg, label_dg, cv=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#out\n",
    "#!git config --global user.email \"antoniomusolino007@gmail.com\"\n",
    "!git add ../.\n",
    "!git commit -m 'Aggiornato grafico cross_val_score'\n",
    "!git push \n",
    "print(out)\n",
    "out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0]*10\n",
    "mean[0] = out[0]\n",
    "for i in range(1,len(out)):\n",
    "    mean[i] = ((mean[i-1] )*i + out[i])/(i+1)\n",
    "\n",
    "plt.plot(out)\n",
    "plt.plot(mean)\n",
    "plt.title('K folder accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('K-Folder')\n",
    "plt.legend(['Real', 'Mean'], loc='lower right')\n",
    "plt.savefig('./K-folder-performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./model_accuracy_40Epoch_scaled',quality=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('./model_loss_40Epoch_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario.save(\"model_dario.h5\")\n",
    "del model_dario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario_reloaded = load_model(\"model_dario.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dario_reloaded = model_dario_reloaded.evaluate_generator(g_dario_test, verbose=1, steps=3)\n",
    "\n",
    "out_dario_reloaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
