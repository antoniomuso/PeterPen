{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "from keras.layers import Dense, LSTM, Dropout, Masking\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "\n",
    "for elem in range(len(data_lines)):\n",
    "    for arr in range(len(data_lines[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_lines[elem][arr][f])\n",
    "        data_lines[elem][arr] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "\n",
    "for elem in range(len(data_circles)):\n",
    "    for arr in range(len(data_circles[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_circles[elem][arr][f])\n",
    "        data_circles[elem][arr] = tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "    \n",
    "\n",
    "def generator(data, labels):\n",
    "    assert len(data) == len(labels)\n",
    "    while True:\n",
    "        for elem in range(len(data)):\n",
    "            #word_array = []\n",
    "            #for arr in range(len(data[elem])):\n",
    "            #    tmp = []\n",
    "            #    for f in range(7):\n",
    "            #        tmp.append(data[elem][arr][f])\n",
    "            #    word_array.append(tmp)\n",
    "            yield np.array(data[elem]), np.array(labels[elem])\n",
    "\n",
    "g_lines = generator(data_lines, [1] * len(data_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "    \n",
    "g_circles = generator(data_circles, [0] * len(data_circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/dati_con_penna/concatenati/pad/dario_1_concat_dario_2_pad.json', 'r') as f:\n",
    "    data_d = json.load(f)\n",
    "    \n",
    "g_dario = generator(data_d[:-3], [1] * 7)\n",
    "g_dario_test = generator(data_d[-3:], [1] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/dati_con_penna/concatenati/pad/antonio_1_concat_antonio_2_pad.json', 'r') as f:\n",
    "    data_a = json.load(f)\n",
    "    \n",
    "g_antonio = generator(data_a[:-3], [0] * 8)\n",
    "g_antonio_test = generator(data_a[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/dati_con_penna/concatenati/pad/manuel_1_concat_manuel_2_pad.json', 'r') as f:\n",
    "    data_t = json.load(f)\n",
    "    \n",
    "g_taraz = generator(data_t[:-3], [0] * 7)\n",
    "g_taraz_test = generator(data_t[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/dati_con_penna/concatenati/pad/giovanni_1_concat_giovanni_2_pad.json', 'r') as f:\n",
    "    data_g = json.load(f)\n",
    "    \n",
    "g_giovanni = generator(data_g[:-3], [0] * 5)\n",
    "g_giovanni_test = generator(data_g[-3:], [0] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_d, labelled_data_g = [], []\n",
    "for i in range(len(data_d)):\n",
    "    labelled_data_d.append((data_d[i], 1))\n",
    "\n",
    "for i in range(len(data_g)):\n",
    "    labelled_data_g.append((data_g[i], 0))\n",
    "    \n",
    "for i in range(len(data_a)):\n",
    "    labelled_data_g.append((data_a[i], 0))\n",
    "\n",
    "for i in range(len(data_t)):\n",
    "    labelled_data_g.append((data_t[i], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_data_dg = labelled_data_d + labelled_data_g  \n",
    "random.shuffle(labelled_data_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 600, 7)\n"
     ]
    }
   ],
   "source": [
    "def xy_data(labelled_data):\n",
    "    x_data, y_labels = [], []\n",
    "    for i in labelled_data:\n",
    "        x_data.append(i[0])\n",
    "        y_labels.append(i[1])\n",
    "        \n",
    "    return np.array(x_data), np.array(y_labels)\n",
    "\n",
    "data_dg, label_dg = xy_data(labelled_data_dg)\n",
    "print(data_dg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_generator(g1, g2, batch_size):\n",
    "    while True:\n",
    "        batch = []\n",
    "        label = []\n",
    "        for _ in range(batch_size // 2):\n",
    "            tmp = next(g1)\n",
    "            batch.append(tmp[0])\n",
    "            label.append(tmp[1])\n",
    "            tmp = next(g2)\n",
    "            batch.append(tmp[0])\n",
    "            label.append(tmp[1])\n",
    "        print(np.array(label).shape)\n",
    "        yield np.array(batch), np.array(label)\n",
    "\n",
    "g_mix = mix_generator(g_lines, g_circles, 10)\n",
    "g_dario_giovanni = mix_generator(g_dario, g_giovanni, 10)\n",
    "g_dario_antonio = mix_generator(g_dario, g_antonio, 10)\n",
    "g_dario_taraz = mix_generator(g_dario, g_taraz, 10)\n",
    "g_dario_giovanni_antonio = mix_generator(g_dario_giovanni, g_dario_antonio, 10)\n",
    "g_dario_tutti = mix_generator(g_dario_giovanni_antonio, g_dario_taraz, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_one_against_all(path_genuine, paths_impostors, batch_size):\n",
    "    with open(path_genuine, 'r') as f:\n",
    "        genuine_data = json.load(f)\n",
    "        \n",
    "    train_ratio = round(len(genuine_data) / 5)\n",
    "    assert len(genuine_data[:-train_ratio]) + len(genuine_data[-train_ratio:]) == len(genuine_data)\n",
    "    genuine_generator = generator(genuine_data[:-train_ratio], [1] * (len(genuine_data) - train_ratio))\n",
    "    genuine_generator_test = generator(genuine_data[-train_ratio:], [1] * train_ratio)\n",
    "    \n",
    "    generator_all = genuine_generator\n",
    "    generator_all_test = genuine_generator_test\n",
    "    \n",
    "    for path in paths_impostors:\n",
    "        with open(path, 'r') as f:\n",
    "            impostor_data = json.load(f)\n",
    "        train_ratio = round(len(impostor_data) / 5)\n",
    "        assert len(impostor_data[:-train_ratio]) + len(impostor_data[-train_ratio:]) == len(impostor_data)\n",
    "        generator_all = mix_generator(generator_all, generator(impostor_data[:-train_ratio], [0] * (len(impostor_data) - train_ratio)), batch_size)\n",
    "        generator_all_test = mix_generator(generator_all_test, generator(impostor_data[-train_ratio:], [0] * train_ratio), batch_size)\n",
    "        \n",
    "    return generator_all, generator_all_test\n",
    "\n",
    "impostors = ['../dati/pad/giovanni_pad.json', '../dati/pad/taraz_pad.json']\n",
    "g_dario_impostors, g_dario_impostors_test = generator_one_against_all('../dati/pad/dario_pad.json', impostors, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    model.add(LSTM(input_shape=(600, 7), units=200, activation=\"sigmoid\", return_sequences=True, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(LSTM(units=200, activation=\"sigmoid\", return_sequences=False, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = KerasClassifier(build_fn=create_model, \n",
    "                                 epochs=4,\n",
    "                                 steps_per_epoch=140,\n",
    "                                 validation_split=0.2,\n",
    "                                 validation_steps=36,\n",
    "                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model_dario, show_shapes=True, to_file='lstm_dropout_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model_dario.fit_generator(g_dario_impostors, epochs=5, steps_per_epoch=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.2777 - acc: 0.8930 - val_loss: 0.0777 - val_acc: 0.9722\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.1186 - acc: 0.9773 - val_loss: 0.0593 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.0811 - acc: 0.9896 - val_loss: 0.0217 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 151s 1s/step - loss: 0.0936 - acc: 0.9887 - val_loss: 0.0831 - val_acc: 0.9722\n",
      "20/20 [==============================] - 0s 15ms/step\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 151s 1s/step - loss: 0.2834 - acc: 0.8912 - val_loss: 0.2220 - val_acc: 0.9444\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 150s 1s/step - loss: 0.1025 - acc: 0.9796 - val_loss: 0.3185 - val_acc: 0.9444\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.1936 - acc: 0.9753 - val_loss: 0.1633 - val_acc: 0.9444\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.3747 - val_acc: 0.9444\n",
      "20/20 [==============================] - 0s 14ms/step\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 150s 1s/step - loss: 0.2836 - acc: 0.8898 - val_loss: 0.1050 - val_acc: 0.9722\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.1171 - acc: 0.9778 - val_loss: 0.2253 - val_acc: 0.9444\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.0439 - acc: 0.9932 - val_loss: 0.2007 - val_acc: 0.9444\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.1167 - acc: 0.9874 - val_loss: 0.2655 - val_acc: 0.9444\n",
      "20/20 [==============================] - 0s 14ms/step\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 150s 1s/step - loss: 0.2909 - acc: 0.8852 - val_loss: 0.1124 - val_acc: 0.9722\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.1072 - acc: 0.9782 - val_loss: 0.1438 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 150s 1s/step - loss: 0.0438 - acc: 0.9942 - val_loss: 0.2383 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 149s 1s/step - loss: 0.0824 - acc: 0.9944 - val_loss: 4.0347 - val_acc: 0.7222\n",
      "20/20 [==============================] - 0s 15ms/step\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.2644 - acc: 0.9013 - val_loss: 0.2584 - val_acc: 0.8611\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.0949 - acc: 0.9805 - val_loss: 0.0396 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.0772 - acc: 0.9912 - val_loss: 0.0491 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 6.8750e-05 - acc: 1.0000 - val_loss: 8.7526 - val_acc: 0.2778\n",
      "20/20 [==============================] - 0s 15ms/step\n",
      "Train on 140 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 154s 1s/step - loss: 0.2658 - acc: 0.8948 - val_loss: 0.2102 - val_acc: 0.9444\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.0877 - acc: 0.9813 - val_loss: 0.1510 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.0575 - acc: 0.9920 - val_loss: 0.2639 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 152s 1s/step - loss: 0.1215 - acc: 0.9867 - val_loss: 0.2389 - val_acc: 0.9444\n",
      "20/20 [==============================] - 0s 16ms/step\n",
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 156s 1s/step - loss: 0.2874 - acc: 0.8870 - val_loss: 0.0893 - val_acc: 0.9444\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.0833 - acc: 0.9865 - val_loss: 0.0587 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.0770 - acc: 0.9908 - val_loss: 0.0279 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.1271 - acc: 0.9850 - val_loss: 0.1272 - val_acc: 0.9722\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 156s 1s/step - loss: 0.2873 - acc: 0.8886 - val_loss: 1.3969 - val_acc: 0.7222\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.1210 - acc: 0.9768 - val_loss: 0.2151 - val_acc: 0.9444\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.0559 - acc: 0.9916 - val_loss: 0.2603 - val_acc: 0.9444\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.1176 - acc: 0.9870 - val_loss: 0.3339 - val_acc: 0.9444\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.3240 - acc: 0.8680 - val_loss: 0.0679 - val_acc: 0.9722\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.1091 - acc: 0.9761 - val_loss: 0.0167 - val_acc: 1.0000\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.1151 - acc: 0.9811 - val_loss: 0.0322 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.0974 - acc: 0.9886 - val_loss: 0.1807 - val_acc: 0.9722\n",
      "19/19 [==============================] - 0s 16ms/step\n",
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/4\n",
      "140/140 [==============================] - 155s 1s/step - loss: 0.3094 - acc: 0.8718 - val_loss: 0.1321 - val_acc: 0.9722\n",
      "Epoch 2/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.0831 - acc: 0.9848 - val_loss: 0.1909 - val_acc: 0.9722\n",
      "Epoch 3/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.0680 - acc: 0.9899 - val_loss: 0.2566 - val_acc: 0.9722\n",
      "Epoch 4/4\n",
      "140/140 [==============================] - 153s 1s/step - loss: 0.2964 - acc: 0.9669 - val_loss: 0.2323 - val_acc: 0.9722\n",
      "19/19 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "#hist = model_dario.fit(x = data_dg, y = label_dg, epochs=40, steps_per_epoch=33, validation_split=0.33, validation_steps=65)\n",
    "\n",
    "out = cross_val_score(neural_network, data_dg, label_dg, cv=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944736897945404"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out\n",
    "#!git config --global user.email \"antoniomusolino007@gmail.com\"\n",
    "#!git add .\n",
    "#!git commit -m 'aggiunti nuovi grafici'\n",
    "#!git push \n",
    "out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./model_accuracy_40Epoch_scaled',quality=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('./model_loss_40Epoch_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario.save(\"model_dario.h5\")\n",
    "del model_dario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dario_reloaded = load_model(\"model_dario.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dario_reloaded = model_dario_reloaded.evaluate_generator(g_dario_test, verbose=1, steps=3)\n",
    "\n",
    "out_dario_reloaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
