{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import keras\n",
    "import random\n",
    "from keras.layers import Dense, LSTM, Dropout, Masking\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "\n",
    "for elem in range(len(data_lines)):\n",
    "    for arr in range(len(data_lines[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_lines[elem][arr][f])\n",
    "        data_lines[elem][arr] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "\n",
    "for elem in range(len(data_circles)):\n",
    "    for arr in range(len(data_circles[elem])):\n",
    "        tmp = []\n",
    "        for f in range(7):\n",
    "            tmp.append(data_circles[elem][arr][f])\n",
    "        data_circles[elem][arr] = tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/lines_pad.json', 'r') as f:\n",
    "    data_lines = json.load(f)\n",
    "\n",
    "with open('../dati/pad/lines_2_pad.json', 'r') as f:\n",
    "    data_lines += json.load(f)\n",
    "    \n",
    "\n",
    "def generator(data, labels):\n",
    "    assert len(data) == len(labels)\n",
    "    while True:\n",
    "        for elem in range(len(data)):\n",
    "            #word_array = []\n",
    "            #for arr in range(len(data[elem])):\n",
    "            #    tmp = []\n",
    "            #    for f in range(7):\n",
    "            #        tmp.append(data[elem][arr][f])\n",
    "            #    word_array.append(tmp)\n",
    "            yield np.array(data[elem]), np.array(labels[elem])\n",
    "\n",
    "g_lines = generator(data_lines, [1] * len(data_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dati/pad/circles_pad.json', 'r') as f:\n",
    "    data_circles = json.load(f)\n",
    "    \n",
    "g_circles = generator(data_circles, [0] * len(data_circles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_recog = 'Manuel_pad.json'\n",
    "file_path = '../dati/scrittura_di_computer/pad/'\n",
    "labelled_data_d, labelled_data_g = [], []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file_recog == file: continue\n",
    "    with open(os.path.join(file_path, file), 'r') as f:\n",
    "        data_g = json.load(f)\n",
    "    for i in range(len(data_g)):\n",
    "        labelled_data_g.append((data_g[i], 0))\n",
    "        \n",
    "        \n",
    "with open(os.path.join(file_path, file_recog), 'r') as f:\n",
    "    data_r = json.load(f)\n",
    "for i in range(len(data_r)):\n",
    "    labelled_data_d.append((data_r[i], 1))\n",
    "    \n",
    "def xy_data(labelled_data):\n",
    "    x_data, y_labels = [], []\n",
    "    for i in labelled_data:\n",
    "        x_data.append(i[0])\n",
    "        y_labels.append(i[1])\n",
    "        \n",
    "    return np.array(x_data), np.array(y_labels)\n",
    "\n",
    "labelled_data_dg = labelled_data_d * 8 + labelled_data_g  \n",
    "random.shuffle(labelled_data_dg)\n",
    "\n",
    "data_dg, label_dg = xy_data(labelled_data_dg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    model.add(LSTM(input_shape=(1000, 7), units=64, activation=\"sigmoid\", return_sequences=True, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(LSTM(units=128, activation=\"sigmoid\", return_sequences=False, recurrent_activation=\"hard_sigmoid\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural_network = KerasClassifier(build_fn=create_model, \n",
    "#                                 epochs=4,\n",
    "#                                 steps_per_epoch=140,\n",
    "#                                 validation_split=0.2,\n",
    "#                                 validation_steps=36,\n",
    "#                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model_dario, show_shapes=True, to_file='lstm_dropout_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist = model_dario.fit_generator(g_dario_impostors, epochs=5, steps_per_epoch=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 389 samples, validate on 193 samples\n",
      "Epoch 1/150\n",
      "389/389 [==============================] - 26s 67ms/step - loss: 0.7274 - acc: 0.5193 - val_loss: 0.7153 - val_acc: 0.4715\n",
      "Epoch 2/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.7159 - acc: 0.4910 - val_loss: 0.6610 - val_acc: 0.7150\n",
      "Epoch 3/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.4356 - acc: 0.8175 - val_loss: 0.3725 - val_acc: 0.9016\n",
      "Epoch 8/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.4054 - acc: 0.8201 - val_loss: 0.3647 - val_acc: 0.8601\n",
      "Epoch 9/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.3055 - acc: 0.8895 - val_loss: 0.2845 - val_acc: 0.9171\n",
      "Epoch 10/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2598 - acc: 0.9100 - val_loss: 0.2194 - val_acc: 0.9171\n",
      "Epoch 11/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1985 - acc: 0.9460 - val_loss: 0.2270 - val_acc: 0.9119\n",
      "Epoch 12/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.3330 - acc: 0.8612 - val_loss: 0.1868 - val_acc: 0.9326\n",
      "Epoch 13/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.1709 - acc: 0.9486 - val_loss: 0.9959 - val_acc: 0.5596\n",
      "Epoch 14/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2533 - acc: 0.8997 - val_loss: 0.3063 - val_acc: 0.8653\n",
      "Epoch 15/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1363 - acc: 0.9537 - val_loss: 1.4549 - val_acc: 0.5285\n",
      "Epoch 16/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2821 - acc: 0.8895 - val_loss: 0.2068 - val_acc: 0.9223\n",
      "Epoch 17/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1411 - acc: 0.9460 - val_loss: 0.2429 - val_acc: 0.8860\n",
      "Epoch 18/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1712 - acc: 0.9486 - val_loss: 0.1960 - val_acc: 0.9430\n",
      "Epoch 19/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0922 - acc: 0.9769 - val_loss: 0.1296 - val_acc: 0.9689\n",
      "Epoch 20/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2395 - acc: 0.8997 - val_loss: 0.1218 - val_acc: 0.9689\n",
      "Epoch 21/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1150 - acc: 0.9692 - val_loss: 0.1064 - val_acc: 0.9689\n",
      "Epoch 22/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1438 - acc: 0.9460 - val_loss: 0.2388 - val_acc: 0.8964\n",
      "Epoch 23/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1013 - acc: 0.9692 - val_loss: 0.1017 - val_acc: 0.9793\n",
      "Epoch 24/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.3073 - acc: 0.9023 - val_loss: 0.1134 - val_acc: 0.9689\n",
      "Epoch 25/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1247 - acc: 0.9640 - val_loss: 0.2378 - val_acc: 0.8808\n",
      "Epoch 26/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1224 - acc: 0.9614 - val_loss: 0.2793 - val_acc: 0.8756\n",
      "Epoch 27/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.2149 - acc: 0.9306 - val_loss: 0.0875 - val_acc: 0.9741\n",
      "Epoch 28/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0610 - acc: 0.9820 - val_loss: 0.5563 - val_acc: 0.8135\n",
      "Epoch 29/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1094 - acc: 0.9589 - val_loss: 0.1057 - val_acc: 0.9689\n",
      "Epoch 30/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1447 - acc: 0.9589 - val_loss: 0.1933 - val_acc: 0.9275\n",
      "Epoch 31/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0719 - acc: 0.9769 - val_loss: 1.3160 - val_acc: 0.6269\n",
      "Epoch 32/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1451 - acc: 0.9512 - val_loss: 0.0800 - val_acc: 0.9793\n",
      "Epoch 33/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1215 - acc: 0.9666 - val_loss: 0.0858 - val_acc: 0.9741\n",
      "Epoch 34/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1711 - acc: 0.9512 - val_loss: 0.1133 - val_acc: 0.9793\n",
      "Epoch 35/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0920 - acc: 0.9743 - val_loss: 0.0841 - val_acc: 0.9793\n",
      "Epoch 36/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0514 - acc: 0.9871 - val_loss: 0.0833 - val_acc: 0.9741\n",
      "Epoch 37/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1413 - acc: 0.9434 - val_loss: 0.0807 - val_acc: 0.9741\n",
      "Epoch 38/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0644 - acc: 0.9769 - val_loss: 0.5598 - val_acc: 0.7306\n",
      "Epoch 39/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.1065 - acc: 0.9486 - val_loss: 0.0924 - val_acc: 0.9689\n",
      "Epoch 40/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0948 - acc: 0.9666 - val_loss: 0.1238 - val_acc: 0.9689\n",
      "Epoch 41/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0325 - acc: 0.9974 - val_loss: 2.7734 - val_acc: 0.5285\n",
      "Epoch 42/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.2984 - acc: 0.9383 - val_loss: 0.1500 - val_acc: 0.9689\n",
      "Epoch 43/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.2320 - acc: 0.9383 - val_loss: 0.0931 - val_acc: 0.9741\n",
      "Epoch 44/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0400 - acc: 0.9923 - val_loss: 0.0725 - val_acc: 0.9741\n",
      "Epoch 45/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1381 - acc: 0.9589 - val_loss: 0.0883 - val_acc: 0.9741\n",
      "Epoch 46/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0614 - acc: 0.9743 - val_loss: 0.0652 - val_acc: 0.9741\n",
      "Epoch 47/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.1027 - acc: 0.9614 - val_loss: 0.0673 - val_acc: 0.9741\n",
      "Epoch 48/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0694 - acc: 0.9666 - val_loss: 0.0779 - val_acc: 0.9741\n",
      "Epoch 49/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0554 - acc: 0.9769 - val_loss: 0.0750 - val_acc: 0.9741\n",
      "Epoch 50/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0480 - acc: 0.9769 - val_loss: 0.6598 - val_acc: 0.8031\n",
      "Epoch 51/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0996 - acc: 0.9692 - val_loss: 0.0738 - val_acc: 0.9741\n",
      "Epoch 52/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0540 - acc: 0.9820 - val_loss: 0.0704 - val_acc: 0.9741\n",
      "Epoch 53/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0147 - acc: 0.9949 - val_loss: 2.9529 - val_acc: 0.5285\n",
      "Epoch 54/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.3723 - acc: 0.9229 - val_loss: 0.3251 - val_acc: 0.9119\n",
      "Epoch 55/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0573 - acc: 0.9820 - val_loss: 0.0819 - val_acc: 0.9741\n",
      "Epoch 56/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1384 - acc: 0.9666 - val_loss: 0.0959 - val_acc: 0.9741\n",
      "Epoch 57/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0287 - acc: 0.9897 - val_loss: 0.0472 - val_acc: 0.9896\n",
      "Epoch 58/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0940 - acc: 0.9769 - val_loss: 0.0575 - val_acc: 0.9741\n",
      "Epoch 59/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0254 - acc: 0.9949 - val_loss: 0.1623 - val_acc: 0.9585\n",
      "Epoch 60/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1117 - acc: 0.9666 - val_loss: 0.0526 - val_acc: 0.9896\n",
      "Epoch 61/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0683 - acc: 0.9794 - val_loss: 0.1147 - val_acc: 0.9741\n",
      "Epoch 62/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0224 - acc: 0.9974 - val_loss: 0.0553 - val_acc: 0.9845\n",
      "Epoch 63/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 0.9896\n",
      "Epoch 64/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0701 - acc: 0.9871 - val_loss: 0.0681 - val_acc: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0459 - acc: 0.9871 - val_loss: 0.0386 - val_acc: 0.9896\n",
      "Epoch 66/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0314 - acc: 0.9923 - val_loss: 0.0571 - val_acc: 0.9793\n",
      "Epoch 67/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9845\n",
      "Epoch 68/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.1374 - acc: 0.9717 - val_loss: 0.0581 - val_acc: 0.9793\n",
      "Epoch 69/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9793\n",
      "Epoch 70/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1135 - acc: 0.9717 - val_loss: 0.0666 - val_acc: 0.9793\n",
      "Epoch 71/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0683 - acc: 0.9692 - val_loss: 0.0537 - val_acc: 0.9793\n",
      "Epoch 72/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0715 - acc: 0.9769 - val_loss: 0.0767 - val_acc: 0.9793\n",
      "Epoch 73/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0475 - val_acc: 0.9896\n",
      "Epoch 74/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9845\n",
      "Epoch 75/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1366 - val_acc: 0.9741\n",
      "Epoch 76/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2610 - acc: 0.9460 - val_loss: 0.0765 - val_acc: 0.9741\n",
      "Epoch 77/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0170 - acc: 0.9949 - val_loss: 0.0532 - val_acc: 0.9793\n",
      "Epoch 78/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0604 - val_acc: 0.9793\n",
      "Epoch 79/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9793\n",
      "Epoch 80/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2032 - acc: 0.9537 - val_loss: 0.2789 - val_acc: 0.8135\n",
      "Epoch 81/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0283 - acc: 0.9923 - val_loss: 0.0460 - val_acc: 0.9845\n",
      "Epoch 82/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 0.9896\n",
      "Epoch 83/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 0.9845\n",
      "Epoch 84/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0777 - val_acc: 0.9845\n",
      "Epoch 85/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 9.3384e-04 - acc: 1.0000 - val_loss: 0.2265 - val_acc: 0.9637\n",
      "Epoch 86/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.4603 - acc: 0.9332 - val_loss: 0.1728 - val_acc: 0.9741\n",
      "Epoch 87/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 0.9845\n",
      "Epoch 88/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1001 - val_acc: 0.9845\n",
      "Epoch 89/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 9.4909e-04 - acc: 1.0000 - val_loss: 0.0927 - val_acc: 0.9845\n",
      "Epoch 90/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2268 - acc: 0.9614 - val_loss: 0.0606 - val_acc: 0.9896\n",
      "Epoch 91/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 0.9845\n",
      "Epoch 92/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 0.9896\n",
      "Epoch 93/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 7.8403e-04 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9845\n",
      "Epoch 94/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 9.8209e-04 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9689\n",
      "Epoch 95/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1516 - acc: 0.9666 - val_loss: 0.0535 - val_acc: 0.9896\n",
      "Epoch 96/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0682 - val_acc: 0.9845\n",
      "Epoch 97/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1197 - acc: 0.9769 - val_loss: 0.1115 - val_acc: 0.9637\n",
      "Epoch 98/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0085 - acc: 0.9949 - val_loss: 3.0250 - val_acc: 0.5492\n",
      "Epoch 99/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.3031 - acc: 0.9563 - val_loss: 0.0803 - val_acc: 0.9845\n",
      "Epoch 100/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 0.9845\n",
      "Epoch 101/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9845\n",
      "Epoch 102/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 9.6871e-04 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9845\n",
      "Epoch 103/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 8.3316e-04 - acc: 1.0000 - val_loss: 0.1088 - val_acc: 0.9845\n",
      "Epoch 104/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0481 - acc: 0.9923 - val_loss: 0.3505 - val_acc: 0.9326\n",
      "Epoch 105/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2007 - acc: 0.9486 - val_loss: 0.1256 - val_acc: 0.9585\n",
      "Epoch 106/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0483 - acc: 0.9794 - val_loss: 0.0583 - val_acc: 0.9845\n",
      "Epoch 107/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9845\n",
      "Epoch 108/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1126 - val_acc: 0.9793\n",
      "Epoch 109/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.1440 - acc: 0.9692 - val_loss: 0.0336 - val_acc: 0.9896\n",
      "Epoch 110/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0382 - acc: 0.9923 - val_loss: 0.0509 - val_acc: 0.9793\n",
      "Epoch 111/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 0.9845\n",
      "Epoch 112/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9845\n",
      "Epoch 113/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 8.4292e-04 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9845\n",
      "Epoch 114/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 4.9876e-04 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9845\n",
      "Epoch 115/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 2.5133e-04 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9845\n",
      "Epoch 116/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2955 - acc: 0.9460 - val_loss: 0.1194 - val_acc: 0.9534\n",
      "Epoch 117/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0189 - acc: 0.9923 - val_loss: 0.0493 - val_acc: 0.9845\n",
      "Epoch 118/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9845\n",
      "Epoch 119/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0215 - acc: 0.9923 - val_loss: 1.0752 - val_acc: 0.7772\n",
      "Epoch 120/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1226 - acc: 0.9666 - val_loss: 0.0488 - val_acc: 0.9845\n",
      "Epoch 121/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 0.9793\n",
      "Epoch 122/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0105 - acc: 0.9974 - val_loss: 0.0805 - val_acc: 0.9793\n",
      "Epoch 123/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0881 - val_acc: 0.9845\n",
      "Epoch 124/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 6.5579e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 4.1822e-04 - acc: 1.0000 - val_loss: 0.1099 - val_acc: 0.9845\n",
      "Epoch 126/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 3.0415e-04 - acc: 1.0000 - val_loss: 0.1234 - val_acc: 0.9845\n",
      "Epoch 127/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2124 - acc: 0.9614 - val_loss: 0.1595 - val_acc: 0.9741\n",
      "Epoch 128/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 0.9845\n",
      "Epoch 129/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 3.7029e-04 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9845\n",
      "Epoch 130/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 3.8333e-04 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 0.9845\n",
      "Epoch 131/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 2.2986e-04 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9845\n",
      "Epoch 132/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 2.3844e-04 - acc: 1.0000 - val_loss: 0.1145 - val_acc: 0.9845\n",
      "Epoch 133/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 1.7282e-04 - acc: 1.0000 - val_loss: 0.1175 - val_acc: 0.9845\n",
      "Epoch 134/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 1.1977e-04 - acc: 1.0000 - val_loss: 0.1357 - val_acc: 0.9845\n",
      "Epoch 135/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.1372 - acc: 0.9640 - val_loss: 0.0846 - val_acc: 0.9534\n",
      "Epoch 136/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0127 - acc: 0.9949 - val_loss: 0.0695 - val_acc: 0.9845\n",
      "Epoch 137/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 0.9845\n",
      "Epoch 138/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 7.9689e-04 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9845\n",
      "Epoch 139/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 3.0907e-04 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9845\n",
      "Epoch 140/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 2.3954e-04 - acc: 1.0000 - val_loss: 0.1140 - val_acc: 0.9845\n",
      "Epoch 141/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 1.2774e-04 - acc: 1.0000 - val_loss: 0.1240 - val_acc: 0.9845\n",
      "Epoch 142/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.2345 - acc: 0.9692 - val_loss: 0.1756 - val_acc: 0.9741\n",
      "Epoch 143/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0305 - acc: 0.9949 - val_loss: 0.9297 - val_acc: 0.8290\n",
      "Epoch 144/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0655 - acc: 0.9871 - val_loss: 0.0886 - val_acc: 0.9845\n",
      "Epoch 145/150\n",
      "389/389 [==============================] - 25s 64ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 0.9845\n",
      "Epoch 146/150\n",
      "389/389 [==============================] - 25s 63ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0942 - val_acc: 0.9845\n",
      "Epoch 147/150\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "cb = keras.callbacks.TensorBoard(log_dir='/usr/Graph', histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch')\n",
    "\n",
    "hist = model.fit(x = data_dg, y = label_dg, epochs=150, batch_size=32, callbacks=[cb],validation_split=0.33)\n",
    "\n",
    "#out = cross_val_score(neural_network, data_dg, label_dg, cv=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#out\n",
    "!git config --global user.email \"antoniomusolino007@gmail.com\"\n",
    "#!git stash --include-untracked\n",
    "!git add ../.\n",
    "!git commit -m 'aggiunto modello giovanni'\n",
    "!git pull\n",
    "!git push \n",
    "#print(out)\n",
    "#out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_mean (curve):\n",
    "    mean = [0]* len(curve)\n",
    "    mean[0] = curve[0]\n",
    "    for i in range(1,len(curve)):\n",
    "        mean[i] = ((mean[i-1] )*i + out[i])/(i+1)\n",
    "    return mean\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model_Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Learn', 'Test'], loc='lower right')\n",
    "plt.savefig('./150_epoch_accuracy_new_data_Manuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./model_accuracy_40Epoch_scaled',quality=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "#plt.savefig('./model_loss_40Epoch_scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_manuel_good_performance.h5')\n",
    "model_dario_reloaded = load_model(\"model_dario_good_performance.h5\")\n",
    "model_antonio_reloaded = load_model('model_antonio_good_performance.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, y = xy_data(labelled_data_g)\n",
    "x1, y1, = xy_data(labelled_data_d)\n",
    "out_dario_reloaded = model_dario_reloaded.evaluate(x, y)\n",
    "out_dario_reloaded2 = model_dario_reloaded.evaluate(x1, y1)\n",
    "\n",
    "print(out_dario_reloaded)\n",
    "print(out_dario_reloaded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../dati/dati_con_penna/concatenati/pad/antonio_1_concat_antonio_2_pad.json', 'r') as f:\n",
    "    attack = json.load(f)\n",
    "\n",
    "attack = np.array(attack)\n",
    "#print(attack.shape)\n",
    "model_dario_reloaded.evaluate(attack, np.zeros(attack.shape[0]))\n",
    "#attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
